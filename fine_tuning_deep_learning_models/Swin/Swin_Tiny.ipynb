{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/manhmitcf/data.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = 'Swin-Tiny'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T04:44:48.330219Z","iopub.execute_input":"2025-04-26T04:44:48.330981Z","iopub.status.idle":"2025-04-26T04:44:48.338809Z","shell.execute_reply.started":"2025-04-26T04:44:48.330953Z","shell.execute_reply":"2025-04-26T04:44:48.337966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom torchvision import transforms\nimport os\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nimport pandas as pd\nfrom PIL import Image\nfrom torch.optim.lr_scheduler import StepLR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T04:44:48.741318Z","iopub.execute_input":"2025-04-26T04:44:48.741605Z","iopub.status.idle":"2025-04-26T04:44:52.078625Z","shell.execute_reply.started":"2025-04-26T04:44:48.741583Z","shell.execute_reply":"2025-04-26T04:44:52.078009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nclass FishDatasetWithAugmentation(Dataset):\n    def __init__(self, csv_file, img_dir, transform=None, aug_transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.aug_transform = aug_transform\n        self.labels = {\"Highly Fresh\" : 0, \"Fresh\" : 1, \"Not Fresh\": 2}  \n        # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o\n        if not os.path.exists(img_dir) :\n            raise FileNotFoundError(f\"Th∆∞ m·ª•c ·∫£nh '{img_dir}' kh√¥ng t·ªìn t·∫°i.\")\n        if self.data.empty:\n            raise ValueError(f\"File CSV '{csv_file}' kh√¥ng ch·ª©a d·ªØ li·ªáu.\")\n        \n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        check = False\n        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 2])\n        if not os.path.exists(img_name):\n            check = True\n        if check:\n            img_name = os.path.join(self.img_dir, self.data.iloc[idx, 2])\n            img_name = img_name.replace('_5', '_#')\n            if not os.path.exists(img_name):\n                raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh '{img_name}'.\")\n        try:\n            image = Image.open(img_name).convert('RGB')  # ƒê·ªçc v√† chuy·ªÉn ƒë·ªïi ·∫£nh sang RGB\n        except FileNotFoundError:\n            raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh '{img_name}'.\")\n\n\n        label = self.data.iloc[idx, 1]\n        if label not in self.labels:\n            raise ValueError(f\"Nh√£n '{label}' kh√¥ng h·ª£p l·ªá. Ph·∫£i l√† m·ªôt trong {list(self.labels.keys())}.\")\n        label = self.labels[label]\n        label = torch.tensor(label, dtype=torch.long)\n        if self.transform:\n            image = self.transform(image)\n        elif self.aug_transform:\n            image = self.aug_transform(image)\n        else:\n            raise ValueError(\"C·∫£ transform v√† aug_transform ƒë·ªÅu l√† None. √çt nh·∫•t m·ªôt trong hai ph·∫£i ƒë∆∞·ª£c cung c·∫•p.\")\n\n        return image, label\nbasic_transform = transforms.Compose([\n        transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.LANCZOS),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\naug_transform = transforms.Compose([\n    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.LANCZOS),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=30),\n    transforms.ColorJitter(brightness=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T04:44:52.079603Z","iopub.execute_input":"2025-04-26T04:44:52.079909Z","iopub.status.idle":"2025-04-26T04:44:52.089981Z","shell.execute_reply.started":"2025-04-26T04:44:52.079891Z","shell.execute_reply":"2025-04-26T04:44:52.089413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import timm\nfrom timm import create_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T04:44:52.090628Z","iopub.execute_input":"2025-04-26T04:44:52.090796Z","iopub.status.idle":"2025-04-26T04:44:53.585463Z","shell.execute_reply.started":"2025-04-26T04:44:52.090782Z","shell.execute_reply":"2025-04-26T04:44:53.584810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport copy\n\nclass EarlyStopping:\n    def __init__(self, patience=20, mode=\"min\"):\n        \"\"\"\n        patience: s·ªë epoch kh√¥ng c·∫£i thi·ªán ƒë·ªÉ d·ª´ng\n        mode: \"min\" cho val_loss (c√†ng th·∫•p c√†ng t·ªët), \"max\" cho val_acc (c√†ng cao c√†ng t·ªët)\n        \"\"\"\n        self.patience = patience\n        self.mode = mode\n        self.best_loss = float(\"inf\")  # ban ƒë·∫ßu gi√° tr·ªã loss r·∫•t l·ªõn\n        self.best_acc = -float(\"inf\")  # ban ƒë·∫ßu gi√° tr·ªã accuracy r·∫•t th·∫•p\n        self.counter = 0\n        self.best_weights = None\n        self.early_stop = False\n\n    def check_improvement(self, val_loss, val_acc, model):\n        \"\"\"\n        Ki·ªÉm tra c·∫£i thi·ªán d·ª±a tr√™n c·∫£ val_loss v√† val_acc.\n        \"\"\"\n        # Ki·ªÉm tra c√≥ c·∫£i thi·ªán `val_loss` ho·∫∑c `val_acc`\n        if val_acc > self.best_acc:\n            # N·∫øu `val_loss` gi·∫£m ho·∫∑c `val_acc` tƒÉng, c·∫≠p nh·∫≠t m√¥ h√¨nh t·ªët nh·∫•t\n            self.best_loss = val_loss\n            self.best_acc = val_acc\n            self.best_weights = copy.deepcopy(model.state_dict())  # L∆∞u l·∫°i tr·ªçng s·ªë c·ªßa m√¥ h√¨nh\n            self.counter = 0  # Reset counter v√¨ ƒë√£ c√≥ c·∫£i thi·ªán\n            return True\n\n        # N·∫øu kh√¥ng c√≥ c·∫£i thi·ªán\n        self.counter += 1\n        if self.counter >= self.patience:\n            self.early_stop = True  # N·∫øu kh√¥ng c√≥ c·∫£i thi·ªán sau `patience` epoch th√¨ d·ª´ng\n        return False\n\n    def restore_best_model(self, model):\n        \"\"\"Kh√¥i ph·ª•c l·∫°i m√¥ h√¨nh t·ªët nh·∫•t\"\"\"\n        if self.best_weights is not None:\n            model.load_state_dict(self.best_weights)\n            print(\"Restored best model weights.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T04:44:53.586895Z","iopub.execute_input":"2025-04-26T04:44:53.587178Z","iopub.status.idle":"2025-04-26T04:44:53.594067Z","shell.execute_reply.started":"2025-04-26T04:44:53.587158Z","shell.execute_reply":"2025-04-26T04:44:53.593324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n# C·∫•u h√¨nh\nTRAIN_CSV_PATH = \"data/train.csv\"\nVAL_CSV_PATH = \"data/val.csv\"\nIMG_DIR = \"data/images/\"\nEPOCHS = 100\nBATCH_SIZE = 64\nLEARNING_RATE = 1e-4\nNUM_CLASSES = 3\nearly_stopper = EarlyStopping(patience=20, mode=\"min\")  # Ho·∫∑c \"max\" n·∫øu b·∫°n mu·ªën theo d√µi accuracy\nepoch = None \n# Dataset v√† DataLoader\ntrain_dataset = FishDatasetWithAugmentation(\n    csv_file=TRAIN_CSV_PATH,\n    img_dir=IMG_DIR,\n    transform=None,\n    aug_transform=aug_transform,  \n)\n\nval_dataset = FishDatasetWithAugmentation(\n    csv_file=VAL_CSV_PATH,\n    img_dir=IMG_DIR,\n    transform=basic_transform,\n)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Model + Loss + Optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = FishClassifier(num_classes=NUM_CLASSES)\n# model.to(device)\nmodel = create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=NUM_CLASSES)\nmodel = model.to(device)\nmodel = torch.nn.DataParallel(model) \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n# Log ƒë·ªÉ l∆∞u l·∫°i loss/acc\n# Log ƒë·ªÉ l∆∞u l·∫°i loss/acc\nloss_train, loss_val = [], []\nacc_train, acc_val = [], []\ntotal_start_time = time.time()\nepoch_times = []\n# Training loop\nfor epoch in range(EPOCHS):\n    epoch_start_time = time.time() \n    # Train\n    model.train()\n    train_running_loss = 0.0\n    train_correct = 0\n    train_total = 0\n    \n    for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS} (Train)\"):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        train_running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n    \n    avg_train_loss = train_running_loss / len(train_dataloader)\n    train_accuracy = 100 * train_correct / train_total\n\n    # Validation\n    model.eval()\n    val_running_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    \n    with torch.no_grad():\n        for images, labels in val_dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n    \n    avg_val_loss = val_running_loss / len(val_dataloader)\n    val_accuracy = 100 * val_correct / val_total\n\n    # L∆∞u log\n    loss_train.append(avg_train_loss)\n    loss_val.append(avg_val_loss)\n    acc_train.append(train_accuracy)\n    acc_val.append(val_accuracy)\n\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    print(f\"    Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n    print(f\"    Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n    # Sau khi t√≠nh avg_val_loss v√† val_accuracy\n    if early_stopper.check_improvement(avg_val_loss, val_accuracy, model):\n        print(\"Improved! Saving best model.\")\n    else:\n        print(f\"No improvement for {early_stopper.counter} epochs.\")\n\n    # N·∫øu kh√¥ng c·∫£i thi·ªán trong `patience` epochs, d·ª´ng s·ªõm v√† kh√¥i ph·ª•c m√¥ h√¨nh t·ªët nh·∫•t\n    if early_stopper.early_stop:\n        print(\"Early stopping triggered.\")\n        early_stopper.restore_best_model(model)\n        break\n    epoch_end_time = time.time()\n    epoch_duration = epoch_end_time - epoch_start_time\n    epoch_times.append(epoch_duration)  # L∆∞u th·ªùi gian epoch n√†y\n# T√≠nh th·ªùi gian k·∫øt th√∫c to√†n b·ªô training\ntotal_end_time = time.time()\ntotal_duration = total_end_time - total_start_time\nprint(f\"\\n‚è≥ Total training time: {total_duration/60:.2f} minutes.\")\n# Trung b√¨nh th·ªùi gian 1 epoch\navg_epoch_time = sum(epoch_times) / len(epoch_times)\nprint(f\"‚è±Ô∏è Average time per epoch: {avg_epoch_time:.2f} seconds (~{avg_epoch_time/60:.2f} minutes)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T04:44:56.701443Z","iopub.execute_input":"2025-04-26T04:44:56.701760Z","iopub.status.idle":"2025-04-26T05:51:51.450901Z","shell.execute_reply.started":"2025-04-26T04:44:56.701725Z","shell.execute_reply":"2025-04-26T05:51:51.450116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\n\n# ƒê·∫£m b·∫£o th∆∞ m·ª•c 'result' t·ªìn t·∫°i\nos.makedirs('result', exist_ok=True)\n\n# V·∫Ω Loss\nplt.figure()\nplt.plot(loss_train, label='Train Loss')\nplt.plot(loss_val, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.legend()\nplt.grid(True)\nplt.savefig('result/loss_curve.png')  # L∆∞u v√†o file\nplt.close()\n\n# V·∫Ω Accuracy\nplt.figure()\nplt.plot(acc_train, label='Train Accuracy')\nplt.plot(acc_val, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy over Epochs')\nplt.legend()\nplt.grid(True)\nplt.savefig('result/accuracy_curve.png')  # L∆∞u v√†o file\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:51.452254Z","iopub.execute_input":"2025-04-26T05:51:51.452531Z","iopub.status.idle":"2025-04-26T05:51:51.788004Z","shell.execute_reply.started":"2025-04-26T05:51:51.452495Z","shell.execute_reply":"2025-04-26T05:51:51.787399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntorch.save(model.state_dict(), f\"result/fish_classifier_{model_name}.pth\")\nprint(\"ƒê√£ l∆∞u m√¥ h√¨nh!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:51.788704Z","iopub.execute_input":"2025-04-26T05:51:51.788896Z","iopub.status.idle":"2025-04-26T05:51:51.947518Z","shell.execute_reply.started":"2025-04-26T05:51:51.788880Z","shell.execute_reply":"2025-04-26T05:51:51.946761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport timm\nimport numpy as np\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n)\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:51.949392Z","iopub.execute_input":"2025-04-26T05:51:51.949673Z","iopub.status.idle":"2025-04-26T05:51:51.954669Z","shell.execute_reply.started":"2025-04-26T05:51:51.949654Z","shell.execute_reply":"2025-04-26T05:51:51.953665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.eval()\n\n# ==== Load dataset test ====\nCSV_PATH = \"data/test.csv\"\nIMG_DIR = \"data/images/\"\n\ntry:\n    dataset = FishDatasetWithAugmentation(CSV_PATH, IMG_DIR, transform=basic_transform)\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\nexcept FileNotFoundError as e:\n    raise FileNotFoundError(f\"L·ªói khi t·∫£i dataset: {e}\")\n\n# ==== D·ª± ƒëo√°n v√† t√≠nh metrics ====\nall_preds, all_labels = [], []\nwith torch.no_grad():\n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        preds = torch.argmax(outputs, dim=1)\n        all_preds.append(preds.cpu().numpy())\n        all_labels.append(labels.cpu().numpy())\n\nall_preds = np.concatenate(all_preds)\nall_labels = np.concatenate(all_labels)\n\nacc = accuracy_score(all_labels, all_preds)\nf1 = f1_score(all_labels, all_preds, average=\"macro\")\nprecision = precision_score(all_labels, all_preds, average=\"macro\")\nrecall = recall_score(all_labels, all_preds, average=\"macro\")\n\nprint(f\"‚úÖ Accuracy:  {acc:.4f}\")\nprint(f\"‚úÖ F1-score:  {f1:.4f}\")\nprint(f\"‚úÖ Precision: {precision:.4f}\")\nprint(f\"‚úÖ Recall:    {recall:.4f}\")\n\n# ==== Classification Report + Confusion Matrix ====\ntry:\n    class_names = [\"Highly Fresh\", \"Fresh\", \"Not Fresh\"]\n    if len(set(all_labels)) > len(class_names):\n        raise ValueError(\"S·ªë l∆∞·ª£ng l·ªõp th·ª±c t·∫ø l·ªõn h∆°n s·ªë l·ªõp ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\")\n    \n    print(\"\\nüìä Classification Report:\\n\")\n    print(classification_report(all_labels, all_preds, target_names=class_names))\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    \n    # V·∫Ω v√† l∆∞u\n    fig, ax = plt.subplots(figsize=(8, 6))  # B·∫°n c√≥ th·ªÉ ch·ªânh k√≠ch th∆∞·ªõc t√πy √Ω\n    disp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax)\n    plt.title(\"Confusion Matrix\")\n    plt.savefig('result/confusion_matrix.png', dpi=300)  # L∆∞u v√†o file PNG\n    plt.close()  # ƒê√≥ng plot ƒë·ªÉ kh√¥ng b·ªã ch·ªìng h√¨nh khi v·∫Ω ti·∫øp\n\n    print(\"‚úÖ ƒê√£ l∆∞u confusion matrix v√†o th∆∞ m·ª•c 'result/'.\")\n\nexcept ValueError as e:\n    print(f\"‚ö†Ô∏è L·ªói trong vi·ªác t·∫°o b√°o c√°o l·ªõp: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:51.955536Z","iopub.execute_input":"2025-04-26T05:51:51.955780Z","iopub.status.idle":"2025-04-26T05:51:58.999090Z","shell.execute_reply.started":"2025-04-26T05:51:51.955757Z","shell.execute_reply":"2025-04-26T05:51:58.998429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimize = \"AdamW\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:58.999839Z","iopub.execute_input":"2025-04-26T05:51:59.000075Z","iopub.status.idle":"2025-04-26T05:51:59.003704Z","shell.execute_reply.started":"2025-04-26T05:51:59.000056Z","shell.execute_reply":"2025-04-26T05:51:59.002998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {\n    \"model_name\": model_name,\n    \"optimizer\": optimize,\n    \"lr\": LEARNING_RATE,\n    \"batch_size\": BATCH_SIZE,\n    \"epochs\": EPOCHS,\n    \"epochs_current\": epoch,\n    \"val_best_acc\": early_stopper.best_acc * 0.01,\n    \"val_best_loss\": early_stopper.best_loss,\n    \"accuracy\": acc,\n    \"precision\": precision,\n    \"recall\": recall,\n    \"f1_score\": f1,\n    \"time(s)\": total_duration,\n    \"time_per_epoch(s)\": avg_epoch_time\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:59.004485Z","iopub.execute_input":"2025-04-26T05:51:59.004670Z","iopub.status.idle":"2025-04-26T05:51:59.018133Z","shell.execute_reply.started":"2025-04-26T05:51:59.004656Z","shell.execute_reply":"2025-04-26T05:51:59.017569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.DataFrame([results])\nresults_df.to_csv(f\"result/evaluation_results_{model_name}.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nfrom datetime import datetime\n\ndef save_model_config(save_dir,config):\n\n    # X√≥a c√°c tr∆∞·ªùng None ƒë·ªÉ file json g·ªçn\n    config = {k: v for k, v in config.items() if v is not None}\n\n    os.makedirs(save_dir, exist_ok=True)\n    save_path = os.path.join(save_dir, f\"{model_name}_config.json\")\n    \n    with open(save_path, 'w') as f:\n        json.dump(config, f, indent=4)\n    \n    print(f\"‚úÖ ƒê√£ l∆∞u file config: {save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = {\n    \"model_name\": model_name,\n    \"input_size\": 224,\n    \"num_classes\": 3,\n    \"batch_size\": BATCH_SIZE,\n    \"learning_rate\": LEARNING_RATE,\n    \"optimizer\": optimize,\n    \"loss_function\": \"CrossEntropyLoss\",\n    \"weight_decay\": 0.02,\n    \"epoch_trained\": epoch,\n    \"best_val_acc\": early_stopper.best_acc * 0.01,\n    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n    \"loss_train\": loss_train,\n    \"loss_val\": loss_val,\n    \"acc_train\": acc_train,\n    \"acc_val\": acc_val\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_model_config(save_dir=\"result\",config = config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nimport shutil\nimport os\n\n# Gi·∫£ s·ª≠ model_name ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a\nzip_filename = f\"result_{model_name}.zip\"\n\n# N√©n folder\nshutil.make_archive(base_name=zip_filename.replace('.zip', ''), format='zip', root_dir='result')\n\n# T·∫°o link t·∫£i\nprint(\"‚úÖ File ƒë√£ s·∫µn s√†ng ƒë·ªÉ t·∫£i:\")\ndisplay(FileLink(zip_filename))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T05:51:59.042316Z","iopub.execute_input":"2025-04-26T05:51:59.042574Z","iopub.status.idle":"2025-04-26T05:52:04.666292Z","shell.execute_reply.started":"2025-04-26T05:51:59.042549Z","shell.execute_reply":"2025-04-26T05:52:04.665657Z"}},"outputs":[],"execution_count":null}]}