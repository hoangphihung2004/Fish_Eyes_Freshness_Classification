{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11288558,"sourceType":"datasetVersion","datasetId":7058331},{"sourceId":11504160,"sourceType":"datasetVersion","datasetId":7212779},{"sourceId":13626172,"sourceType":"datasetVersion","datasetId":8660365}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.io import read_image\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport os\nfrom tqdm import tqdm\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\ndata_transform = transforms.Compose([\n    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.LANCZOS),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/data-split/meta_data_64_16_20.csv\")\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FishClassifier(nn.Module):\n    def __init__(self, num_classes=3):\n        super(FishClassifier, self).__init__()\n        self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n\n        in_features = self.efficientnet.classifier.in_features\n        self.efficientnet.classifier = nn.Linear(in_features, num_classes)\n\n    def forward(self, x):\n        return self.efficientnet(x)\n\nmodel = FishClassifier()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = nn.DataParallel(model)\n\nstate_dict = torch.load(\"/kaggle/input/efficientnet/fish_classifier_EfficientNet-B0.pth\", map_location=device)\n\nmodel.load_state_dict(state_dict)\n\nmodel = model.module\n\nmodel.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EfficientNetFeatureExtractor(nn.Module):\n    def __init__(self, base_model):\n        super().__init__()\n        self.features = nn.Sequential(\n            base_model.conv_stem,\n            base_model.bn1,\n            *list(base_model.blocks[:6])\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) \n        \n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        return x\n        \nextractor = EfficientNetFeatureExtractor(model.efficientnet)\nextractor.eval()\nextractor.to(device)\nextractor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_folder = r\"/kaggle/input/manhmeo/GG/xzyx7pbr3w-1\"\n\nfeatures = []\nlabels = []\npaths = []\ntypes = []\n\nfor i, row in tqdm(df.iterrows(), desc=\"Feature Extraction\"):\n    path = os.path.join(base_folder, row[\"Fish Name\"], row[\"Path\"])\n    try:\n        if not os.path.exists(path):\n            path = path.replace('_5', '_0')\n\n        image = Image.open(path).convert(\"RGB\")\n\n        tensor_image = data_transform(image).unsqueeze(0).to(device)\n\n        with torch.no_grad():\n            features_batch = extractor(tensor_image)\n\n        features.append(features_batch.squeeze(0).cpu().numpy())\n        labels.append(row[\"Label\"])\n        types.append(row[\"Type\"])\n        paths.append(os.path.join(row[\"Fish Name\"], row[\"Path\"]))\n\n    except Exception as e:\n        print(f\"Error at {path}: {e}\")\n\nresults = pd.DataFrame({\"Path\": paths, \"Label\": labels, \"Type\": types})\nresults","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols = [f\"Feature_{i}\" for i in range(192)]\n\ndf1 = pd.DataFrame(features, columns=cols)\ndf1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = pd.concat([results, df1], axis=1)\nnew_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df.to_csv(r\"/kaggle/working/feature_extraction_EfficientNetB0_Block6.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}