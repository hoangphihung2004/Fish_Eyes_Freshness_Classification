{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "from itertools import product\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def modeling(train_set, test_set, label):\n",
    "    train = train_set.copy()\n",
    "    test = test_set.copy()\n",
    "\n",
    "    # Encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    train[label] = label_encoder.fit_transform(train[label])\n",
    "    test[label] = label_encoder.transform(test[label])\n",
    "\n",
    "    # train, validation, test\n",
    "    x_train, y_train = train.drop(columns=[\"Label\", \"Path\", \"Type\"]), train[label]\n",
    "    x_test, y_test = test.drop(columns=[\"Label\", \"Path\", \"Type\"]), test[label]\n",
    "\n",
    "    # features\n",
    "    features_name = list(x_train.columns)\n",
    "\n",
    "    # Normalization\n",
    "    scaler_ = StandardScaler()\n",
    "    x_train = scaler_.fit_transform(x_train)\n",
    "    x_test = scaler_.transform(x_test)\n",
    "\n",
    "    x_train = pd.DataFrame(x_train, columns=features_name)\n",
    "    x_test = pd.DataFrame(x_test, columns=features_name)\n",
    "\n",
    "    param_RF = {\"n_estimators\": np.random.randint(10, 501, size=300),\n",
    "                \"max_depth\": np.random.randint(2, 50, size=25),\n",
    "                \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "    param_SVC = {\"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "                 \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "                 'gamma': ['scale', 'auto'],\n",
    "                 'coef0': [0.0, 0.01, 0.1]\n",
    "                }\n",
    "\n",
    "    param_KNN = {\"n_neighbors\": [3, 5, 7, 9, 11, 15, 17, 19, 21, 23],\n",
    "                 \"weights\": [\"uniform\", \"distance\"],\n",
    "                 \"metric\": ['euclidean', 'manhattan', 'chebyshev', \"minkowski\"],\n",
    "                 \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                 }\n",
    "\n",
    "    param_LGBM = {\"boosting_type\": [\"gbdt\", \"dart\"],\n",
    "                  \"num_leaves\": np.random.randint(15, 50, size=25),\n",
    "                  \"max_depth\": np.random.randint(2, 50, size=25),\n",
    "                  \"learning_rate\": [0.001, 0.01, 0.1, 1, 10],\n",
    "                  \"n_estimators\": np.random.randint(10, 501, size=300),\n",
    "                  \"class_weight\": [\"balanced\", None],\n",
    "                  }\n",
    "\n",
    "    param_ET = {\"n_estimators\": np.random.randint(10, 501, size=300),\n",
    "                \"max_depth\": [None, 10, 15, 20, 25, 30, 35, 40, 50],\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"min_samples_split\": [2, 3, 5, 7, 9, 11],\n",
    "                \"min_samples_leaf\": [1, 3, 5, 8, 9, 11],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"max_leaf_nodes\": [None, 2, 3, 4, 5, 6, 8, 9, 10, 11]}\n",
    "\n",
    "    param_CB = {'iterations': np.random.randint(300, 1000, size=25),\n",
    "                'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5],\n",
    "                'depth': [4, 6, 8, 10],\n",
    "                'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "                'bagging_temperature': [0, 0.5, 1, 2],\n",
    "                'random_strength': [1, 5, 10],\n",
    "                'border_count': [32, 64, 128],\n",
    "                'grow_policy': [\"SymmetricTree\", \"Depthwise\"],\n",
    "                'loss_function': [\"MultiClass\"],\n",
    "                'eval_metric': [\"Accuracy\"],\n",
    "                'task_type': [\"CPU\"],\n",
    "                'devices': ['0'],\n",
    "                'verbose': [False]\n",
    "                }\n",
    "\n",
    "    param_LR = {\"penalty\": [\"l1\", \"l2\"],\n",
    "                \"C\": [0.01, 0.1, 1.0, 10, 100],\n",
    "                \"solver\": [\"liblinear\", \"saga\"],\n",
    "                \"max_iter\": np.random.randint(300, 800, size=25)}\n",
    "\n",
    "    param_ANN = {\"hidden_layer_sizes\": [(64,), (100,), (128,), (256,)],\n",
    "                 \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "                 \"solver\": [\"adam\", \"sgd\", \"lbfgs\"],\n",
    "                 \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "                 \"max_iter\": [800, 1000, 1500, 1700],\n",
    "                 \"learning_rate\": [\"constant\", \"adaptive\", \"invscaling\"],\n",
    "                 \"early_stopping\": [True],}\n",
    "\n",
    "    models = {\n",
    "        \"CatBoost\": (CatBoostClassifier(), param_CB, 50),\n",
    "        \"KNN\": (KNeighborsClassifier(), param_KNN, 50),\n",
    "        \"LR\": (LogisticRegression(), param_LR, 50),\n",
    "        \"ANN\": (MLPClassifier(), param_ANN, 50),\n",
    "        \"LGBM\": (LGBMClassifier(objective=\"multiclass\", force_col_wise=True, verbose=-1), param_LGBM, 50),\n",
    "        \"SVM\": (SVC(), param_SVC, 50),\n",
    "        \"RF\": (RandomForestClassifier(), param_RF, 50),\n",
    "        \"EXTree\": (ExtraTreesClassifier(verbose=0), param_ET, 50),\n",
    "    }\n",
    "\n",
    "    result = {\"Model\": [],\n",
    "\n",
    "              \"Precision Test\": [],\n",
    "              \"Recall Test\": [],\n",
    "              \"F1-score Test\": [],\n",
    "              \"Accuracy Test\": [],\n",
    "              \"Best Param\": []}\n",
    "\n",
    "    for name, model in tqdm(models.items(), desc=\"Modeling\"):\n",
    "        keys, values = zip(*model[1].items())\n",
    "        all_combinations = list(product(*values))\n",
    "\n",
    "        all_combinations = random.sample(all_combinations, model[2])\n",
    "\n",
    "        temp_results = []\n",
    "\n",
    "        for i, v in tqdm(enumerate(all_combinations), desc=f\"Random Search - {name}\"):\n",
    "\n",
    "            params = dict(zip(keys, v))\n",
    "\n",
    "            if name == \"CatBoost\":\n",
    "                model_instance = CatBoostClassifier()\n",
    "            else:\n",
    "                model_instance = model[0].set_params(**params)\n",
    "            model_instance.fit(x_train, y_train)\n",
    "\n",
    "            y_pre_test = model_instance.predict(x_test)\n",
    "\n",
    "            temp_results.append({\n",
    "                \"Model\": name,\n",
    "\n",
    "                \"Precision Test\": precision_score(y_test, y_pre_test, average=\"weighted\"),\n",
    "                \"Recall Test\": recall_score(y_test, y_pre_test, average=\"weighted\"),\n",
    "                \"F1-score Test\": f1_score(y_test, y_pre_test, average=\"weighted\"),\n",
    "                \"Accuracy Test\": accuracy_score(y_test, y_pre_test),\n",
    "                \"Best Param\": model_instance.get_params()\n",
    "            })\n",
    "\n",
    "        top_results = sorted(temp_results, key=lambda x: x[\"Accuracy Test\"], reverse=True)[0]\n",
    "\n",
    "        result[\"Model\"].append(top_results[\"Model\"])\n",
    "\n",
    "        result[\"Precision Test\"].append(top_results[\"Precision Test\"])\n",
    "        result[\"Recall Test\"].append(top_results[\"Recall Test\"])\n",
    "        result[\"F1-score Test\"].append(top_results[\"F1-score Test\"])\n",
    "        result[\"Accuracy Test\"].append(top_results[\"Accuracy Test\"])\n",
    "\n",
    "        result[\"Best Param\"].append(top_results[\"Best Param\"])\n",
    "\n",
    "    return pd.DataFrame(result)"
   ],
   "id": "4d237b2d05c2e0e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(r\"Fish_Eyes_Freshness_Classification\\machine_learning\\Swin\\feature_extraction_Swin_Stage4.csv\")\n",
    "\n",
    "df_train = df.loc[(df[\"Type\"] == \"Train\")].copy()\n",
    "df_test = df.loc[df[\"Type\"] == \"Test\"].copy()\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ],
   "id": "15eee5a9db2b0e71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_result = modeling(train_set=df_train, test_set=df_test, label=\"Label\")\n",
    "\n",
    "final_result"
   ],
   "id": "85a890568ece3059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_result.to_csv(r\"Fish_Eyes_Freshness_Classification\\machine_learning\\Swin\\result_feature_extraction_Swin_Stage4.csv\", index=False)",
   "id": "d994f975992f693a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c9ded67e286434f9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
